#  -*- mode: org -*-
#+STARTUP: indent

* TODO 

directories ls: if lock ordering problem, return what we have read so far

error codes
  e.g., write cnt = 0 should return which error happened

check that inodes are not modified on disk on abort
  e.g., nlink on failure to add to dir

test for reallocating inode before shrunk

mtime

end-to-end tests for recovery

goosify

simplify allocator, plan 1
  goal: avoid locking regions; no search for free object as part of txn
    txn never issues reads to bitmaps (except at recovery time)
    txn contains single-bit writes to freed or allocated blocks
  in-memory allocator state: list of free object IDs (block#s, inode#s)
    probably map[uint64]struct{}
  invariant: in-memory allocator state (set of free object IDs) is a
    subset of the on-disk allocator state (set of free bits in bitmap)
  allocation returns one of the in-memory IDs, and marks it in-use
  after allocating an object ID, add txn write to the allocated bitmap bit
  if txn aborts, return allocated IDs to the in-memory allocator state
  when freeing object, add txn write to the freed bitmap bit
  after txn commits, put freed IDs into the in-memory allocator state
  on recovery, populate in-memory allocator state from on-disk bitmap

smallfile() in cmd/clnt-smallfile/main.go and cmd/smallfile/main.go
  make nfs_clnt.go support both, avoiding redundancy

log-by-pass writes


* Some performance

** running on ext3 over image in tmpfs

[tmp]$ rm nfs3.img 
[tmp]$ dd if=/dev/zero of=nfs3.img bs=4K count=100000
[tmp]$ mkfs -t ext3 nfs3.img
[tmp]$ sudo mount -t ext3 -o data=journal,sync -o loop /tmp/nfs3.img /srv/nfs/bench
[tmp]$ sudo systemctl start nfs-server.service
[tmp]$ sudo mount -t nfs -o vers=3 localhost:/srv/nfs/bench /mnt/nfs
[tmp]$ sudo chmod 777 /srv/nfs/bench

[bench (master)]$ ~/hack/fscq-impl/bench/largefile /mnt/nfs
makefile 50 MB 295276 usec throughput 173397.1 KB/s
writefile 50 MB 168222 usec throughput 304359.7 KB/s

** parallel lookup 

[goose-nfs (master)]$ go run ./cmd/lookup/main.go
Lookup: 385771 file in 1000000 usec with 1 threads
Lookup: 593760 file in 1000000 usec with 2 threads
Lookup: 771640 file in 1000000 usec with 3 threads
Lookup: 809043 file in 1000000 usec with 4 threads

** NULL RPC

[goose-nfs (master)]$ go run ./cmd/clnt-smallfile/main.go 
null: 33551 getattr in 1000000 usec

** <2020-01-24 Fri>: smallfile (including remove)

# Linux loopback
$ ./run-linux.sh  go run ./cmd/fs-smallfile/main.go
fs-smallfile: 3168.5 file/sec

[goose-nfs (master)]$ ./run-linux.sh  go run ./cmd/fs-largefile/main.go
run go run ./cmd/fs-largefile/main.go
fs-largefile: 50 MB througput 208.43 MB/s

# goose-nfsd over loopback
[goose-nfs (master)]$ ./run-goose-nfs.sh  go run ./cmd/fs-smallfile/main.go
2020/01/24 06:52:03 MkFsSuper: open file disk /dev/shm/goose.img
2020/01/24 06:52:04 NFS Null
2020/01/24 06:52:04 Null
2020/01/24 06:52:04 Null
2020/01/24 06:52:04 Mount /
2020/01/24 06:52:04 NFS Null
go run ./cmd/fs-smallfile/main.go
fs-smallfile: 2606.6 file/sec

[goose-nfs (master)]$ ./run-goose-nfs.sh go run ./cmd/fs-largefile/main.go
go run ./cmd/fs-largefile/main.go
fs-largefile: 50 MB througput 112.85 MB/s

Most time is spent in Go's GC
Linux sends several 4-KB NFS Write RPCs in parallel

# in-server goose-nfsd
[goose-nfs (master)]$ go run ./cmd/smallfile/main.go 
2020/01/24 06:54:43 MkFsSuper: open file disk /dev/shm/goose4d65822107fcfd52.img
smallfile: 8443.1 file/swith 1 threads

[goose-nfs (master)]$ go run ./cmd/largefile/main.go 
2020/01/24 09:20:06 MkFsSuper: open file disk /dev/shm/goose4d65822107fcfd52.img
largefile: 50 MB througput 322.07 MB/s

# NFS client

[goose-nfs (master)]$ ./run-goose-clnt.sh  go run ./cmd/clnt-smallfile/main.go 
2020/01/24 07:01:49 MkFsSuper: open file disk /dev/shm/goose.img
go run ./cmd/clnt-smallfile/main.go
2020/01/24 07:01:50 Mount /
root fh {[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]}
clnt-smallfile: 2784.5 file/s

